{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"210409 scikit_optimize_stock_price_finished.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oeBYWfb8-I3P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yarwogvt-svQ"},"source":["## Load data"]},{"cell_type":"markdown","metadata":{"id":"k7qO0dP0xc98"},"source":["### Modules for the stock program"]},{"cell_type":"code","metadata":{"id":"tcbD2jpN_FIQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617956294761,"user_tz":-540,"elapsed":22738,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"1abf2568-0a36-4b3f-e66c-c9b1d67c5785"},"source":["!pip install scikit-optimize"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting scikit-optimize\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n","\r\u001b[K     |███▎                            | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.5MB/s \n","\u001b[?25hCollecting pyaml>=16.9\n","  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LlH2UylMxT4X"},"source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM,Dropout, Conv1D, Lambda, GRU\n","from tensorflow.keras.losses import Huber\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhMhFlAXxiMH"},"source":["# window_size(전일 몇일치 데이터로 예측할 것인가)를 이용해서 LSTM에 필요한 데이터셋을 만들어주는 모듈\n","# Module for making batched data which can be used in LSTM Machine learning. - 4 columns\n","def making_batch(data_x, data_y, window_size):\n","  # 사용법 : X_data_batch, y_data_batch = making_batch(data_x, data_y, 50)\n","  # ndarray 만을 넣어야 함.\n","  new_data_x = []\n","  new_data_y = []\n","  for i in range(len(data_x) - window_size):\n","    _x = data_x[i: i+window_size]\n","    _y = data_y[i+window_size]\n","    new_data_x.append(_x)\n","    new_data_y.append(_y)\n","  new_data_x = np.array(new_data_x)\n","  new_data_y = np.array(new_data_y)\n","  return new_data_x, new_data_y\n","\n","# 종가만으로 batch 만드는 프로그램. - 1 columns (only the close price)\n","def making_batch_pr(data_y, window_size):\n","  new_data_x = []\n","  new_data_y = []\n","  for i in range(len(data) - window_size):\n","    _x = data_y[i: i+window_size] # 종가 20일치\n","    _y = data_y[i+window_size] # 그다음 하루의 종가\n","    new_data_x.append(_x) # 20일치 x에 넣고\n","    new_data_y.append(_y) # 1일치 y에 넣는다.\n","  return new_data_x, new_data_y\n","# window_size 만큼의 x 데이터의 결과값이 y[window_size+1] 이 된다.\n","# 즉 그 전날 60일만큼의 데이터가 그 다음의 주가를 예측한다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMw-Ct25xkX2"},"source":["# 데이터를 가져오는 함수# 데이터를 가져오는 모듈\n","def getting_data(need_date='all'):\n","  # need_date 로는 필요한 일수를 입력한다.\n","  samsung = pd.read_csv('./A005930.csv')\n","  cols = ['DAY','CUR_PR','HIGH_PR','LOW_PR','CLO_PR','FOR_STOR']\n","  samsung = samsung[cols]\n","  samsung = samsung.rename(columns = {'DAY':'date','CUR_PR':'open','HIGH_PR':'high','LOW_PR':'low','CLO_PR':'close','FOR_STOR':'volume'})\n","  samsung.sort_values(by='date', inplace=True)\n","  samsung.reset_index(drop=True, inplace=True)\n","  if need_date=='all':\n","    return samsung\n","  else:\n","    samsung = samsung[-need_date:]\n","    samsung.reset_index(drop=True, inplace=True)\n","    return samsung\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VrAftwkx6it"},"source":["# 기존 모델\n","def create_model_GRU(input_shape, dropout_rate,\n","                 num_first_LSTM_nodes, num_second_LSTM_nodes, \n","                 activation='relu',learning_rate=0.00001):\n","  model = Sequential()\n","  model.add(GRU(units = num_first_LSTM_nodes, activation=activation, return_sequences = True, input_shape=input_shape))\n","  # LSTM 1층\n","  #model.add(Dropout(dropout_rate))\n","  # 드롭아웃 층\n","  model.add(GRU(units = num_second_LSTM_nodes, activation=activation))\n","  # LSTM 2층\n","  #model.add(Dropout(dropout_rate))\n","  model.add(Dense(units = 1)) # 출력증\n","\n","  adam = Adam(lr=learning_rate)\n","  loss=Huber()\n","  model.compile(optimizer=adam, loss=loss)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQiP0coa4Kaj"},"source":["# 모델 구조 만드는 모듈\n","# the usual imports for a vanilla nueral net\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import tensorflow\n","from tensorflow.python.keras import backend as K\n","from keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfV7VF8A7jpk"},"source":["window_size = 30"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woLSUI-fxl6X"},"source":["def create_model(learning_rate, num_dense_layers,num_input_nodes,\n","                 num_dense_nodes, activation, adam_decay): # adam_decay - 학습율 조정과 관련된 파라미터.\n","    #start the model making process and create our first layer\n","    model = Sequential()\n","    # input shape 에 (window_size, column 갯수) 를 넣어준다.\n","    model.add(LSTM(units = num_input_nodes, input_shape= (30,4), activation=activation, return_sequences=True))\n","    # input_shape 을 따로 넣어줘야 한다.\n","    # 첫번째 층 완료.\n","\n","    #create a loop making a new dense layer for the amount passed to this model.\n","    #naming the layers helps avoid tensorflow error deep in the stack trace.\n","    for i in range(num_dense_layers):\n","      # 몇층으로 할지,\n","        name = 'layer_dense_{0}'.format(i+1)\n","        model.add(Dense(num_dense_nodes,\n","                 activation=activation,\n","                        name=name\n","                 ))\n","    #add our classification layer.\n","    model.add(Dense(units=1))\n","    # 여기 노드수 1로 해야 하고, 활성화함수는 없어야 함.\n","    \n","    #setup our optimizer and compile\n","    adam = Adam(lr=learning_rate, decay= adam_decay)\n","    loss=Huber()\n","    model.compile(optimizer=adam, loss=loss,\n","                 metrics=['accuracy'])\n","    # 주식은 loss 에 Huber() 객체를 넣어주는 듯 함.\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rz4kEQAN3w7G"},"source":["#imports we know we'll need\n","import skopt\n","from skopt import gbrt_minimize, gp_minimize\n","from skopt.utils import use_named_args\n","from skopt.space import Real, Categorical, Integer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqM2bC713noq"},"source":["# skopt 안의 space 는 범위를 지정해주는 틀이다.\n","# 지정해주면 그 사이 값으로 skopt 모듈의 최적화기가 무작위로 알아서 넣어준다.\n","dim_learning_rate = Real(low=1e-4, high=1e-1, prior='log-uniform',\n","                         name='learning_rate')\n","dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n","dim_num_input_nodes = Integer(low=1, high=512, name='num_input_nodes')\n","dim_num_dense_nodes = Integer(low=1, high=28, name='num_dense_nodes')\n","dim_activation = Categorical(categories=['relu', 'sigmoid'],\n","                             name='activation')\n","dim_batch_size = Integer(low=1, high=128, name='batch_size')\n","dim_adam_decay = Real(low=1e-6,high=1e-2,name=\"adam_decay\")\n","\n","dimensions = [dim_learning_rate,\n","              dim_num_dense_layers,\n","              dim_num_input_nodes,\n","              dim_num_dense_nodes,\n","              dim_activation,\n","              dim_batch_size,\n","              dim_adam_decay\n","             ]\n","default_parameters = [1e-3, 1,512, 13, 'relu',64, 1e-3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwA_Oixp8I5s","executionInfo":{"status":"ok","timestamp":1617961763772,"user_tz":-540,"elapsed":962,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"6baea2ea-2b83-40bf-e88f-697d0d6aeda9"},"source":["samsung = getting_data(700)\n","samsung\n","\n","cols_for_scaling = ['open','high','low','close','volume']\n","scaler = MinMaxScaler()\n","scaled_samsung = scaler.fit_transform(samsung[cols_for_scaling])\n","scaled_samsung = pd.DataFrame(scaled_samsung, columns=cols_for_scaling, index=samsung['date'])\n","scaled_samsung\n","\n","data_cols = ['open','high','low','volume']\n","target_cols = ['close']\n","X_data = scaled_samsung[data_cols]\n","y_data = scaled_samsung[target_cols]\n","window_size=30\n","\n","new_X_data, new_y_data = making_batch(X_data.values, y_data.values, window_size)\n","print(\"X:\",new_X_data.shape)\n","print(\"y:\",new_y_data.shape)\n","\n","input_shape = new_X_data.shape[1:]\n","\n","# 최근 100일이 테스트셋, 100일 전까지의 데이터는 트레이닝셋\n","test_date = 100\n","X_train = new_X_data[:-test_date]\n","X_test = new_X_data[-test_date:]\n","y_train = new_y_data[:-test_date]\n","y_test = new_y_data[-test_date:]\n","\n","# # train_data_set 과 val_data_set 을 나누자.\n","# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X: (670, 30, 4)\n","y: (670, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G3UA62ix3v7l"},"source":["@use_named_args(dimensions=dimensions)\n","def fitness(learning_rate, num_dense_layers, num_input_nodes, \n","            num_dense_nodes,activation, batch_size,adam_decay):\n","  # fitting(훈련) 시키는 메소드인 듯.\n","\n","    model = create_model(\n","                         learning_rate=learning_rate, # 최적화기의 학습율 지정\n","                         num_dense_layers=num_dense_layers, # 밀집층을 몇개의 층으로 할 거냐.\n","                         num_input_nodes=num_input_nodes, # 입력층의 노드 갯수 지정\n","                         num_dense_nodes=num_dense_nodes, # 밀집층(히든층)의 노드 갯수 지정\n","                         activation=activation, # 밀집층의 활성화함수로는 뭘 쓸 것이냐 (주식에선 보통 relu 씀)\n","                         adam_decay=adam_decay # 이건 뭐지??\n","                        )\n","    \n","\n","    #named blackbox becuase it represents the structure\n","    # 만든 모델로 학습을 진행해준다.\n","    blackbox = model.fit(x=X_train, # 훈련 데이터를 넣어준다.\n","                        y=y_train, # 정답을 넣어준다.\n","                        epochs=3, # 몇회 돌릴 것인지 넣어준다.\n","                        batch_size=batch_size, # 배치 사이즈는 몇개로 할 것인지 (부분집합 갯수)\n","                        validation_split=0.15, # validation 데이터로 얼마나 분할할 것인지.\n","                        )\n","    #return the validation accuracy for the last epoch.\n","    loss = blackbox.history['val_loss'][-1] # val_accuracy 를 따로 담아준다. (출력하여 보기 위함)\n","\n","    # Print the classification accuracy.\n","    print()\n","    print(\"loss: {0:.2}\".format(loss))\n","    print()\n","\n","\n","    # Delete the Keras model with these hyper-parameters from memory.\n","    del model \n","    \n","    # Clear the Keras session, otherwise it will keep adding new\n","    # models to the same TensorFlow graph each time we create\n","    # a model with a different set of hyper-parameters.\n","    K.clear_session()\n","    tensorflow.compat.v1.reset_default_graph()\n","    # 이거 안하면 하이퍼파라미터 초기화가 안되서\n","    # 새로운 텐서플로우 모델이 생기지 않음.\n","    # 그래서 항상 clear 해줘야 함.\n","    \n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdTv5AEi85O5"},"source":["# 이 코드를 텐서플로우에 항상 넣어주는게 좋다는데?\n","# 그래야 문제가 안일어난데.\n","K.clear_session()\n","tensorflow.compat.v1.reset_default_graph()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwu-lwS589V5","executionInfo":{"status":"ok","timestamp":1617962351885,"user_tz":-540,"elapsed":108381,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"3ed606a1-04e8-4722-e1e1-b4c33f8b862d"},"source":["gp_result = gp_minimize(func=fitness,\n","                            dimensions=dimensions,\n","                            n_calls=12,\n","                            noise= 0.01,\n","                            n_jobs=-1,\n","                            kappa = 5,\n","                            x0=default_parameters)\n","# dimensions 안에 파라미터들이 다 들어가 있음.\n","# fitness 의 출력물로는 -1*정확도가 나옴.\n","# 즉, -1*정확도가 최소화가 되는 방향이 곧 정확도가 가장 높은 방향이다.\n","# 그래서 gp_minimize 라는 함수를 통해 정확도의 최대값을 구한다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","8/8 [==============================] - 3s 146ms/step - loss: 0.0087 - accuracy: 0.0032 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","8/8 [==============================] - 1s 112ms/step - loss: 0.0031 - accuracy: 0.0018 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","8/8 [==============================] - 1s 105ms/step - loss: 0.0027 - accuracy: 0.0018 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n","\n","loss: 0.0044\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","6/6 [==============================] - 2s 155ms/step - loss: 83.0586 - accuracy: 9.0429e-04 - val_loss: 0.0872 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","6/6 [==============================] - 0s 84ms/step - loss: 0.0507 - accuracy: 0.0026 - val_loss: 0.0338 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","6/6 [==============================] - 1s 88ms/step - loss: 0.0078 - accuracy: 0.0018 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n","\n","loss: 0.015\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","6/6 [==============================] - 3s 188ms/step - loss: 5.0128 - accuracy: 0.0042 - val_loss: 0.0526 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","6/6 [==============================] - 1s 98ms/step - loss: 0.0144 - accuracy: 0.0026 - val_loss: 0.0336 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","6/6 [==============================] - 1s 108ms/step - loss: 0.0068 - accuracy: 0.0042 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n","\n","loss: 0.0076\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","5/5 [==============================] - 2s 165ms/step - loss: 0.1425 - accuracy: 6.8871e-04 - val_loss: 0.0893 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 0s 80ms/step - loss: 0.0469 - accuracy: 0.0010 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 0s 76ms/step - loss: 0.0170 - accuracy: 6.8871e-04 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n","\n","loss: 0.0039\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","10/10 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.0013WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9d51279440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","10/10 [==============================] - 3s 154ms/step - loss: 0.0196 - accuracy: 0.0014 - val_loss: 0.0572 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","10/10 [==============================] - 1s 108ms/step - loss: 0.0177 - accuracy: 3.7566e-04 - val_loss: 0.0397 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","10/10 [==============================] - 1s 104ms/step - loss: 0.0099 - accuracy: 0.0018 - val_loss: 0.0362 - val_accuracy: 0.0000e+00\n","\n","loss: 0.036\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","16/16 [==============================] - 4s 143ms/step - loss: 0.8277 - accuracy: 3.6957e-04 - val_loss: 0.7008 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","16/16 [==============================] - 2s 97ms/step - loss: 0.4579 - accuracy: 0.0046 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","16/16 [==============================] - 2s 96ms/step - loss: 0.2106 - accuracy: 0.0019 - val_loss: 0.1902 - val_accuracy: 0.0000e+00\n","\n","loss: 0.19\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","61/61 [==============================] - 8s 98ms/step - loss: 0.0063 - accuracy: 0.0025 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","61/61 [==============================] - 5s 89ms/step - loss: 0.0044 - accuracy: 0.0013 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","61/61 [==============================] - 6s 90ms/step - loss: 0.0046 - accuracy: 0.0020 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n","\n","loss: 0.016\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","5/5 [==============================] - 3s 200ms/step - loss: 0.1435 - accuracy: 0.0016 - val_loss: 0.0524 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 0s 93ms/step - loss: 0.0706 - accuracy: 0.0011 - val_loss: 0.1265 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 0s 95ms/step - loss: 0.0430 - accuracy: 0.0041 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n","\n","loss: 0.0023\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","15/15 [==============================] - 3s 121ms/step - loss: 0.0179 - accuracy: 0.0062 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","15/15 [==============================] - 1s 92ms/step - loss: 0.0032 - accuracy: 0.0020 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","15/15 [==============================] - 1s 93ms/step - loss: 0.0021 - accuracy: 5.3097e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n","\n","loss: 0.003\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","5/5 [==============================] - 3s 197ms/step - loss: 0.1381 - accuracy: 0.0022 - val_loss: 0.0608 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 0s 102ms/step - loss: 0.0126 - accuracy: 0.0010 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 0s 97ms/step - loss: 0.0144 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n","\n","loss: 0.0016\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","8/8 [==============================] - 3s 143ms/step - loss: 0.1336 - accuracy: 0.0034 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","8/8 [==============================] - 1s 85ms/step - loss: 0.0386 - accuracy: 0.0010 - val_loss: 0.0341 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","8/8 [==============================] - 1s 81ms/step - loss: 0.0128 - accuracy: 0.0024 - val_loss: 0.0346 - val_accuracy: 0.0000e+00\n","\n","loss: 0.035\n","\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","484/484 [==============================] - 13s 25ms/step - loss: 0.0215 - accuracy: 0.0014 - val_loss: 0.0602 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","484/484 [==============================] - 12s 25ms/step - loss: 0.0191 - accuracy: 5.0789e-04 - val_loss: 0.0585 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","484/484 [==============================] - 12s 25ms/step - loss: 0.0174 - accuracy: 3.9170e-04 - val_loss: 0.0574 - val_accuracy: 0.0000e+00\n","\n","loss: 0.057\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1M7VmVobAGyd","executionInfo":{"status":"ok","timestamp":1617962353983,"user_tz":-540,"elapsed":843,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"c2b4a095-4133-4d80-9f62-996a35e26ade"},"source":["gp_result.fun"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.001606404664926231"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q3kNTtro-4uY","executionInfo":{"status":"ok","timestamp":1617962354595,"user_tz":-540,"elapsed":914,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"d40839a7-c370-44cd-f35c-4b2fe2e4b7fb"},"source":["gp_result"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          fun: 0.001606404664926231\n","    func_vals: array([0.00439719, 0.01519386, 0.0075621 , 0.00390762, 0.03622856,\n","       0.1901671 , 0.01554267, 0.00233966, 0.00304531, 0.0016064 ,\n","       0.03458865, 0.05739554])\n","       models: [GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n","                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=0.01),\n","                         n_restarts_optimizer=2, noise=0.01, normalize_y=True,\n","                         optimizer='fmin_l_bfgs_b', random_state=767162376), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n","                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=0.01),\n","                         n_restarts_optimizer=2, noise=0.01, normalize_y=True,\n","                         optimizer='fmin_l_bfgs_b', random_state=767162376)]\n"," random_state: RandomState(MT19937) at 0x7F9DFC6E3050\n","        space: Space([Real(low=0.0001, high=0.1, prior='log-uniform', transform='normalize'),\n","       Integer(low=1, high=5, prior='uniform', transform='normalize'),\n","       Integer(low=1, high=512, prior='uniform', transform='normalize'),\n","       Integer(low=1, high=28, prior='uniform', transform='normalize'),\n","       Categorical(categories=('relu', 'sigmoid'), prior=None),\n","       Integer(low=1, high=128, prior='uniform', transform='normalize'),\n","       Real(low=1e-06, high=0.01, prior='uniform', transform='normalize')])\n","        specs: {'args': {'func': <function fitness at 0x7f9d57243b90>, 'dimensions': Space([Real(low=0.0001, high=0.1, prior='log-uniform', transform='normalize'),\n","       Integer(low=1, high=5, prior='uniform', transform='normalize'),\n","       Integer(low=1, high=512, prior='uniform', transform='normalize'),\n","       Integer(low=1, high=28, prior='uniform', transform='normalize'),\n","       Categorical(categories=('relu', 'sigmoid'), prior=None),\n","       Integer(low=1, high=128, prior='uniform', transform='normalize'),\n","       Real(low=1e-06, high=0.01, prior='uniform', transform='normalize')]), 'base_estimator': GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n","                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5),\n","                         n_restarts_optimizer=2, noise=0.01, normalize_y=True,\n","                         optimizer='fmin_l_bfgs_b', random_state=767162376), 'n_calls': 12, 'n_random_starts': None, 'n_initial_points': 10, 'initial_point_generator': 'random', 'acq_func': 'gp_hedge', 'acq_optimizer': 'auto', 'x0': [0.001, 1, 512, 13, 'relu', 64, 0.001], 'y0': None, 'random_state': RandomState(MT19937) at 0x7F9DFC6E3050, 'verbose': False, 'callback': None, 'n_points': 10000, 'n_restarts_optimizer': 5, 'xi': 0.01, 'kappa': 5, 'n_jobs': -1, 'model_queue_size': None}, 'function': 'base_minimize'}\n","            x: [0.022207201170733794, 3, 277, 3, 'sigmoid', 118, 0.004802287735881647]\n","      x_iters: [[0.001, 1, 512, 13, 'relu', 64, 0.001], [0.026973444993248854, 1, 146, 5, 'relu', 91, 0.001693386725199919], [0.008572598930954274, 4, 321, 13, 'relu', 90, 0.0030805928016799764], [0.010323225741269527, 2, 29, 16, 'sigmoid', 116, 0.002378302811105906], [0.0009176120776416789, 4, 476, 9, 'relu', 49, 0.009242594711436933], [0.0029539098970038295, 4, 494, 8, 'sigmoid', 31, 0.004815029236857353], [0.00027787443014504827, 5, 502, 15, 'sigmoid', 8, 0.0022119286244206724], [0.040678548083215096, 5, 87, 20, 'sigmoid', 102, 0.004237187961407204], [0.007216359146872774, 1, 448, 12, 'relu', 34, 0.008763227541677365], [0.022207201170733794, 3, 277, 3, 'sigmoid', 118, 0.004802287735881647], [0.007891422386009893, 4, 180, 18, 'sigmoid', 61, 0.007943637154697892], [0.0001, 1, 1, 28, 'relu', 1, 0.01]]"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfKomv4L-LIG","executionInfo":{"status":"ok","timestamp":1617962378960,"user_tz":-540,"elapsed":791,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"890f4efe-b9c3-4720-d0b7-25e5bd2ff71d"},"source":["print(\"best loss was \" + str((gp_result.fun)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["best loss was 0.001606404664926231\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4iqIHHm-RHl","executionInfo":{"status":"ok","timestamp":1617962356810,"user_tz":-540,"elapsed":919,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"fdc33278-aaa8-4c0a-c200-9dc99cad9127"},"source":["gp_result.x # 최적의 하이퍼파라미터를 출력해준다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.022207201170733794, 3, 277, 3, 'sigmoid', 118, 0.004802287735881647]"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll25c3c-THy","executionInfo":{"status":"ok","timestamp":1617962357559,"user_tz":-540,"elapsed":994,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"da6df11c-b7bb-45ee-dc18-6ea13c3324b3"},"source":["gp_result.func_vals # 최적의 하이퍼 파라미터로 했을 때 교차검증(또는 에포크수에 따른)한 정확도들을 보여준다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.00439719, 0.01519386, 0.0075621 , 0.00390762, 0.03622856,\n","       0.1901671 , 0.01554267, 0.00233966, 0.00304531, 0.0016064 ,\n","       0.03458865, 0.05739554])"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"UhMppOsQ-VPu","executionInfo":{"status":"ok","timestamp":1617962558197,"user_tz":-540,"elapsed":1046,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"2d015fc5-07a9-460c-f845-3ccdcfa521be"},"source":["import pandas as pd\n","pd.concat([pd.DataFrame(gp_result.x_iters, columns = [\"learning rate\",\"hidden layers\",\"input layer nodes\",\"hidden layer nodes\",\n","                                           \"activation function\",\"batch size\",\"adam learning rate decay\"]),\n","(pd.Series(gp_result.func_vals, name=\"loss\"))], axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>learning rate</th>\n","      <th>hidden layers</th>\n","      <th>input layer nodes</th>\n","      <th>hidden layer nodes</th>\n","      <th>activation function</th>\n","      <th>batch size</th>\n","      <th>adam learning rate decay</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.001000</td>\n","      <td>1</td>\n","      <td>512</td>\n","      <td>13</td>\n","      <td>relu</td>\n","      <td>64</td>\n","      <td>0.001000</td>\n","      <td>0.004397</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.026973</td>\n","      <td>1</td>\n","      <td>146</td>\n","      <td>5</td>\n","      <td>relu</td>\n","      <td>91</td>\n","      <td>0.001693</td>\n","      <td>0.015194</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.008573</td>\n","      <td>4</td>\n","      <td>321</td>\n","      <td>13</td>\n","      <td>relu</td>\n","      <td>90</td>\n","      <td>0.003081</td>\n","      <td>0.007562</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.010323</td>\n","      <td>2</td>\n","      <td>29</td>\n","      <td>16</td>\n","      <td>sigmoid</td>\n","      <td>116</td>\n","      <td>0.002378</td>\n","      <td>0.003908</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000918</td>\n","      <td>4</td>\n","      <td>476</td>\n","      <td>9</td>\n","      <td>relu</td>\n","      <td>49</td>\n","      <td>0.009243</td>\n","      <td>0.036229</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.002954</td>\n","      <td>4</td>\n","      <td>494</td>\n","      <td>8</td>\n","      <td>sigmoid</td>\n","      <td>31</td>\n","      <td>0.004815</td>\n","      <td>0.190167</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.000278</td>\n","      <td>5</td>\n","      <td>502</td>\n","      <td>15</td>\n","      <td>sigmoid</td>\n","      <td>8</td>\n","      <td>0.002212</td>\n","      <td>0.015543</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.040679</td>\n","      <td>5</td>\n","      <td>87</td>\n","      <td>20</td>\n","      <td>sigmoid</td>\n","      <td>102</td>\n","      <td>0.004237</td>\n","      <td>0.002340</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.007216</td>\n","      <td>1</td>\n","      <td>448</td>\n","      <td>12</td>\n","      <td>relu</td>\n","      <td>34</td>\n","      <td>0.008763</td>\n","      <td>0.003045</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.022207</td>\n","      <td>3</td>\n","      <td>277</td>\n","      <td>3</td>\n","      <td>sigmoid</td>\n","      <td>118</td>\n","      <td>0.004802</td>\n","      <td>0.001606</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.007891</td>\n","      <td>4</td>\n","      <td>180</td>\n","      <td>18</td>\n","      <td>sigmoid</td>\n","      <td>61</td>\n","      <td>0.007944</td>\n","      <td>0.034589</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.000100</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>28</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>0.010000</td>\n","      <td>0.057396</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    learning rate  hidden layers  ...  adam learning rate decay      loss\n","0        0.001000              1  ...                  0.001000  0.004397\n","1        0.026973              1  ...                  0.001693  0.015194\n","2        0.008573              4  ...                  0.003081  0.007562\n","3        0.010323              2  ...                  0.002378  0.003908\n","4        0.000918              4  ...                  0.009243  0.036229\n","5        0.002954              4  ...                  0.004815  0.190167\n","6        0.000278              5  ...                  0.002212  0.015543\n","7        0.040679              5  ...                  0.004237  0.002340\n","8        0.007216              1  ...                  0.008763  0.003045\n","9        0.022207              3  ...                  0.004802  0.001606\n","10       0.007891              4  ...                  0.007944  0.034589\n","11       0.000100              1  ...                  0.010000  0.057396\n","\n","[12 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6Ulgwt5-WzC","executionInfo":{"status":"ok","timestamp":1617960728802,"user_tz":-540,"elapsed":1069,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"fbd1d388-7deb-493c-8b19-1173c3fdf625"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.001, 1, 512, 13, 'relu', 64, 0.001]"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"EjimOQ5b-swv"},"source":["Creating our search parameters.\n","\"dim_\" short for dimension. Its' just a way to label our parameters.\n","\n","We can search across nearly every param in a keras model. \n","This code focuses on: \n","* Number of Layers\n","* Number of Nodes per layer\n","* Learning Rate & Weight Decay for the Adam Optimizer\n","* activation functions\n","* batch size\n","\n","The name feature allows us to use the `@use_named_args` decorator.\n","We must also establish default parameters. "]},{"cell_type":"code","metadata":{"id":"2LG4Mat5-sxL"},"source":["# 이 코드를 텐서플로우에 항상 넣어주는게 좋다는데?\n","# 그래야 문제가 안일어난데.\n","K.clear_session()\n","tensorflow.compat.v1.reset_default_graph()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-dzN6mW-sxQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617956985391,"user_tz":-540,"elapsed":713272,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"f08af118-11b9-462a-f8fc-c9f0ab1a98a8"},"source":["# The explanation for the parameters in gp_minimize method\n","\n","gp_result = gp_minimize(func=fitness,\n","                            dimensions=dimensions,\n","                            n_calls=12,\n","                            noise= 0.01,\n","                            n_jobs=-1,\n","                            kappa = 5,\n","                            x0=default_parameters)\n","# dimensions 안에 파라미터들이 다 들어가 있음.\n","# fitness 의 출력물로는 -1*정확도가 나옴.\n","# 즉, -1*정확도가 최소화가 되는 방향이 곧 정확도가 가장 높은 방향이다.\n","# 그래서 gp_minimize 라는 함수를 통해 정확도의 최대값을 구한다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","797/797 [==============================] - 4s 4ms/step - loss: 0.5460 - accuracy: 0.8372 - val_loss: 0.1344 - val_accuracy: 0.9634\n","Epoch 2/3\n","797/797 [==============================] - 3s 4ms/step - loss: 0.1314 - accuracy: 0.9613 - val_loss: 0.1101 - val_accuracy: 0.9670\n","Epoch 3/3\n","797/797 [==============================] - 3s 4ms/step - loss: 0.0855 - accuracy: 0.9765 - val_loss: 0.0885 - val_accuracy: 0.9751\n","\n","Accuracy: 97.51%\n","\n","Epoch 1/3\n","1822/1822 [==============================] - 8s 4ms/step - loss: 1.1361 - accuracy: 0.6138 - val_loss: 0.3122 - val_accuracy: 0.9106\n","Epoch 2/3\n","1822/1822 [==============================] - 7s 4ms/step - loss: 0.3289 - accuracy: 0.9052 - val_loss: 0.2524 - val_accuracy: 0.9294\n","Epoch 3/3\n","1822/1822 [==============================] - 7s 4ms/step - loss: 0.2730 - accuracy: 0.9212 - val_loss: 0.2302 - val_accuracy: 0.9358\n","\n","Accuracy: 93.58%\n","\n","Epoch 1/3\n","981/981 [==============================] - 5s 4ms/step - loss: 0.9781 - accuracy: 0.6593 - val_loss: 0.3182 - val_accuracy: 0.9056\n","Epoch 2/3\n","981/981 [==============================] - 4s 4ms/step - loss: 0.3382 - accuracy: 0.9025 - val_loss: 0.2696 - val_accuracy: 0.9212\n","Epoch 3/3\n","981/981 [==============================] - 4s 4ms/step - loss: 0.2847 - accuracy: 0.9192 - val_loss: 0.2408 - val_accuracy: 0.9308\n","\n","Accuracy: 93.08%\n","\n","Epoch 1/3\n","750/750 [==============================] - 3s 4ms/step - loss: 0.6687 - accuracy: 0.7936 - val_loss: 0.1494 - val_accuracy: 0.9558\n","Epoch 2/3\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1297 - accuracy: 0.9624 - val_loss: 0.1148 - val_accuracy: 0.9673\n","Epoch 3/3\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0840 - accuracy: 0.9760 - val_loss: 0.1098 - val_accuracy: 0.9694\n","\n","Accuracy: 96.94%\n","\n","Epoch 1/3\n","928/928 [==============================] - 4s 4ms/step - loss: 2.2701 - accuracy: 0.2387 - val_loss: 2.0818 - val_accuracy: 0.4631\n","Epoch 2/3\n","928/928 [==============================] - 3s 4ms/step - loss: 2.0377 - accuracy: 0.4674 - val_loss: 1.9163 - val_accuracy: 0.5267\n","Epoch 3/3\n","928/928 [==============================] - 3s 4ms/step - loss: 1.8820 - accuracy: 0.5298 - val_loss: 1.7834 - val_accuracy: 0.5778\n","\n","Accuracy: 57.78%\n","\n","Epoch 1/3\n","486/486 [==============================] - 3s 5ms/step - loss: 2.3085 - accuracy: 0.1096 - val_loss: 2.3021 - val_accuracy: 0.1063\n","Epoch 2/3\n","486/486 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1063\n","Epoch 3/3\n","486/486 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1063\n","\n","Accuracy: 10.63%\n","\n","Epoch 1/3\n","561/561 [==============================] - 3s 4ms/step - loss: 0.6914 - accuracy: 0.7733 - val_loss: 0.2387 - val_accuracy: 0.9303\n","Epoch 2/3\n","561/561 [==============================] - 2s 4ms/step - loss: 0.2614 - accuracy: 0.9220 - val_loss: 0.2018 - val_accuracy: 0.9417\n","Epoch 3/3\n","561/561 [==============================] - 2s 4ms/step - loss: 0.2222 - accuracy: 0.9336 - val_loss: 0.1972 - val_accuracy: 0.9427\n","\n","Accuracy: 94.27%\n","\n","Epoch 1/3\n","911/911 [==============================] - 4s 4ms/step - loss: 0.7113 - accuracy: 0.7606 - val_loss: 0.1819 - val_accuracy: 0.9524\n","Epoch 2/3\n","911/911 [==============================] - 4s 4ms/step - loss: 0.1606 - accuracy: 0.9559 - val_loss: 0.1421 - val_accuracy: 0.9641\n","Epoch 3/3\n","911/911 [==============================] - 4s 4ms/step - loss: 0.1117 - accuracy: 0.9699 - val_loss: 0.1284 - val_accuracy: 0.9709\n","\n","Accuracy: 97.09%\n","\n","Epoch 1/3\n","6375/6375 [==============================] - 21s 3ms/step - loss: 1.7907 - accuracy: 0.5065 - val_loss: 1.3164 - val_accuracy: 0.7077\n","Epoch 2/3\n","6375/6375 [==============================] - 20s 3ms/step - loss: 1.2839 - accuracy: 0.6972 - val_loss: 1.1593 - val_accuracy: 0.7439\n","Epoch 3/3\n","6375/6375 [==============================] - 20s 3ms/step - loss: 1.1531 - accuracy: 0.7356 - val_loss: 1.0791 - val_accuracy: 0.7657\n","\n","Accuracy: 76.57%\n","\n","Epoch 1/3\n","810/810 [==============================] - 4s 4ms/step - loss: 1.7948 - accuracy: 0.2437 - val_loss: 1.3579 - val_accuracy: 0.4057\n","Epoch 2/3\n","810/810 [==============================] - 3s 4ms/step - loss: 1.3548 - accuracy: 0.3942 - val_loss: 1.2094 - val_accuracy: 0.4326\n","Epoch 3/3\n","810/810 [==============================] - 3s 4ms/step - loss: 1.2203 - accuracy: 0.4220 - val_loss: 1.1245 - val_accuracy: 0.4431\n","\n","Accuracy: 44.31%\n","\n","Epoch 1/3\n","2550/2550 [==============================] - 9s 3ms/step - loss: 0.8273 - accuracy: 0.7221 - val_loss: 0.2905 - val_accuracy: 0.9251\n","Epoch 2/3\n","2550/2550 [==============================] - 9s 3ms/step - loss: 0.3037 - accuracy: 0.9205 - val_loss: 0.2467 - val_accuracy: 0.9358\n","Epoch 3/3\n","2550/2550 [==============================] - 8s 3ms/step - loss: 0.2600 - accuracy: 0.9329 - val_loss: 0.2269 - val_accuracy: 0.9394\n","\n","Accuracy: 93.94%\n","\n","Epoch 1/3\n","51000/51000 [==============================] - 166s 3ms/step - loss: 2.0756 - accuracy: 0.1934 - val_loss: 1.8941 - val_accuracy: 0.2123\n","Epoch 2/3\n","51000/51000 [==============================] - 165s 3ms/step - loss: 1.8862 - accuracy: 0.2250 - val_loss: 1.8427 - val_accuracy: 0.2322\n","Epoch 3/3\n","51000/51000 [==============================] - 165s 3ms/step - loss: 1.8478 - accuracy: 0.2412 - val_loss: 1.8176 - val_accuracy: 0.2462\n","\n","Accuracy: 24.62%\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vTdXkFuI-sxT"},"source":["## Find our best accuracy"]},{"cell_type":"code","metadata":{"id":"7i8FASt4-sxU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617956985397,"user_tz":-540,"elapsed":713257,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"ade9b1f2-81f3-4387-a23a-8399858fc0ae"},"source":["print(\"best accuracy was \" + str(round(gp_result.fun *-100,2))+\"%.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["best accuracy was 97.51%.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hxcpgZ_J-sxb"},"source":["### returning the parameters for the best function"]},{"cell_type":"code","metadata":{"id":"lwP-7nBw-sxe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617956985399,"user_tz":-540,"elapsed":713249,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"6003f587-6e07-4221-9b64-aa6d679eecf5"},"source":["gp_result.x # 최적의 하이퍼파라미터를 출력해준다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.001, 1, 512, 13, 'relu', 64, 0.001]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"5LUuxS20-sxj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617956985402,"user_tz":-540,"elapsed":713242,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"737a7af6-d2b4-4dbb-9ec9-a2d689a738c9"},"source":["gp_result.func_vals # 최적의 하이퍼 파라미터로 했을 때 교차검증(또는 에포크수에 따른)한 정확도들을 보여준다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.97511113, -0.93577778, -0.93077779, -0.96944445, -0.5777778 ,\n","       -0.10633333, -0.94266665, -0.97088891, -0.76566666, -0.44311112,\n","       -0.93944442, -0.24622223])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"6gvnzgwQ-sx1"},"source":["## Trying a gradient boosted search with a simpler model"]},{"cell_type":"code","metadata":{"id":"cWAfSXK2-sx5"},"source":["# Using gbrt (which is a optimization technology with boosting technology)\n","gbrt_result = gbrt_minimize(func=fitness,\n","                            dimensions=dimensions,\n","                            n_calls=12,\n","                            n_jobs=-1,\n","                            x0=default_parameters)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLn_Ch9Q-sx8"},"source":["print(\"best accuracy was \" + str(round(gbrt_result.fun *100,2))+\"%.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnYQgxEU-syC"},"source":["pd.concat([pd.DataFrame(gbrt_result.x_iters, columns = [\"learning rate\",\"hidden layers\",\"input layer nodes\",\"hidden layer nodes\",\n","                                           \"activation function\",\"batch size\",\"adam learning rate decay\"]),\n","(pd.Series(gbrt_result.func_vals*-100, name=\"accuracy\"))], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STbuVKjZ-syG"},"source":["gbrt_result.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-dqCDwg-syM"},"source":["K.clear_session()\n","tensorflow.reset_default_graph()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQyoUwxA-syP"},"source":["#call our best model \n","gbrt_model = create_model(gbrt_result.x[0],gbrt_result.x[1],gbrt_result.x[2],gbrt_result.x[3],gbrt_result.x[4],gbrt_result.x[5])\n","gbrt_model.summary()\n","#retrain our best model architecture\n","model.fit(X_train,y_train, epochs=3)\n","model.evaluate(X_test,y_test)"],"execution_count":null,"outputs":[]}]}